<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>CIC-IDS2017使用DNN进行分类 | Liu's Secret Blog</title><meta name="author" content="iKun"><meta name="copyright" content="iKun"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="数据集介绍CIC-IDS2017数据集数据采集期从2017年7月3日星期一上午9点开始，到2017年7月7日星期五下午5点结束，共5天。星期一这天只包括正常的流量。该数据集实现的攻击包括暴力FTP、暴力SSH、DoS、Heartbleed、Web攻击、渗透、僵尸网络和DDoS。他们分别于周二、周三、周四和周五上午和下午被执行。  周一：只包含良性流量 周二：攻击+正常活动 上午：FTP-Patat">
<meta property="og:type" content="article">
<meta property="og:title" content="CIC-IDS2017使用DNN进行分类">
<meta property="og:url" content="https://liuhengfeng.xyz/posts/6a858c3d.html">
<meta property="og:site_name" content="Liu&#39;s Secret Blog">
<meta property="og:description" content="数据集介绍CIC-IDS2017数据集数据采集期从2017年7月3日星期一上午9点开始，到2017年7月7日星期五下午5点结束，共5天。星期一这天只包括正常的流量。该数据集实现的攻击包括暴力FTP、暴力SSH、DoS、Heartbleed、Web攻击、渗透、僵尸网络和DDoS。他们分别于周二、周三、周四和周五上午和下午被执行。  周一：只包含良性流量 周二：攻击+正常活动 上午：FTP-Patat">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://statics.liuhengfeng.xyz/Hexo/u%3D1968668429%2C2104382916%26fm%3D253%26fmt%3Dauto%26app%3D138%26f%3DJPEG.webp">
<meta property="article:published_time" content="2024-09-20T05:40:09.000Z">
<meta property="article:modified_time" content="2024-09-23T13:50:09.000Z">
<meta property="article:author" content="iKun">
<meta property="article:tag" content="CIC-IDS2017">
<meta property="article:tag" content="异常检测分类">
<meta property="article:tag" content="DNN">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://statics.liuhengfeng.xyz/Hexo/u%3D1968668429%2C2104382916%26fm%3D253%26fmt%3Dauto%26app%3D138%26f%3DJPEG.webp"><link rel="shortcut icon" href="https://statics.liuhengfeng.xyz/Hexo/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240907191402.jpg"><link rel="canonical" href="https://liuhengfeng.xyz/posts/6a858c3d.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":280},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体中文","cht_to_chs":"你已切换为简体中文","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-right"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: true,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'CIC-IDS2017使用DNN进行分类',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-09-23 21:50:09'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 7 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://statics.liuhengfeng.xyz/css/universe.css"><span id="fps"></span><link rel="stylesheet" href="https://statics.liuhengfeng.xyz/css/hexo_electric_clock.css"><link rel="stylesheet" href="https://cdn1.tianli0.top/npm/element-ui@2.15.6/packages/theme-chalk/lib/index.css"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css"/>
<style>#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags:before {content:"\A";
  white-space: pre;}#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags > .article-meta__separator{display:none}</style>
<link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.css" /><link rel="stylesheet" href="https://unpkg.zhimg.com/hexo-butterfly-footer-beautify@1.0.0/lib/runtime.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/animate.min.css" media="print" onload="this.media='screen'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://statics.liuhengfeng.xyz/Hexo/u%3D1968668429%2C2104382916%26fm%3D253%26fmt%3Dauto%26app%3D138%26f%3DJPEG.webp" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">22</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">18</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="Liu's Secret Blog"><img class="site-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://statics.liuhengfeng.xyz/Hexo/71324098a20dbb13870ea57a6bf0f7a0.jpeg"/><span class="site-name">Liu's Secret Blog</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">CIC-IDS2017使用DNN进行分类</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-09-20T05:40:09.000Z" title="发表于 2024-09-20 13:40:09">2024-09-20</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-09-23T13:50:09.000Z" title="更新于 2024-09-23 21:50:09">2024-09-23</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%A7%91%E7%A0%94/">科研</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%A7%91%E7%A0%94/%E5%AE%9E%E9%AA%8C/">实验</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">4.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>20分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="CIC-IDS2017使用DNN进行分类"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="数据集介绍"><a href="#数据集介绍" class="headerlink" title="数据集介绍"></a>数据集介绍</h2><p>CIC-IDS2017数据集数据采集期从2017年7月3日星期一上午9点开始，到2017年7月7日星期五下午5点结束，共5天。星期一这天只包括正常的流量。该数据集实现的攻击包括暴力FTP、暴力SSH、DoS、Heartbleed、Web攻击、渗透、僵尸网络和DDoS。他们分别于周二、周三、周四和周五上午和下午被执行。</p>
<ul>
<li>周一：只包含良性流量</li>
<li>周二：攻击+正常活动<ul>
<li>上午：<strong>FTP-Patator</strong> </li>
<li>下午： <strong>SSH-Patator</strong></li>
</ul>
</li>
</ul>
<ul>
<li><p>周三：攻击+正常活动</p>
<ul>
<li><strong>DoS &#x2F; DDoS</strong>、<strong>Heartbleed</strong></li>
</ul>
</li>
<li><p>周四：攻击+正常活动</p>
<ul>
<li>上午：<strong>Web Attack</strong>（<strong>Brute Force</strong>、<strong>XSS</strong> 、<strong>Sql Injection</strong>） </li>
<li>下午：渗透（<strong>Cool disk</strong>、<strong>Dropbox download</strong>）</li>
</ul>
</li>
<li><p>周五：攻击+正常活动</p>
<ul>
<li>上午：僵尸网络（<strong>Botnet ARES</strong>）</li>
<li>下午：<strong>Port Scan</strong>、<strong>DDoS LOIT</strong></li>
</ul>
</li>
</ul>
<p><u><strong>后续只使用周一、周二、周三、周五的数据进行实验</strong></u> ,不包括周四，因为周四的种类又多每种类型的数量又少，麻烦</p>
<h4 id="特征"><a href="#特征" class="headerlink" title="特征"></a>特征</h4><p>数据集一共有79个特征，最后一列特征 <strong>Label</strong>是标签，<strong>BENIGN</strong>属于正常流量，其他值都是异常流量。所有特征值都是数值型（除了标签列Label），包含大量的0和负值，数据差异很大，要进行归一化处理。</p>
<h4 id="数据集攻击类型分布情况"><a href="#数据集攻击类型分布情况" class="headerlink" title="数据集攻击类型分布情况"></a>数据集攻击类型分布情况</h4><table>
<thead>
<tr>
<th align="left">类型</th>
<th align="left">数量</th>
<th align="left">百分比</th>
<th align="center">Week Days</th>
</tr>
</thead>
<tbody><tr>
<td align="left">BENIGN</td>
<td align="left">2273097</td>
<td align="left">80.300366</td>
<td align="center">Monday to Friday</td>
</tr>
<tr>
<td align="left">DoS Hulk</td>
<td align="left">231073</td>
<td align="left">8.162981</td>
<td align="center">Wednesday</td>
</tr>
<tr>
<td align="left">PortScan</td>
<td align="left">158930</td>
<td align="left">5.614427</td>
<td align="center">Friday</td>
</tr>
<tr>
<td align="left">DDoS</td>
<td align="left">128027</td>
<td align="left">4.522735</td>
<td align="center">Friday</td>
</tr>
<tr>
<td align="left">DoS GoldenEye</td>
<td align="left">10293</td>
<td align="left">0.363615</td>
<td align="center">Wednesday</td>
</tr>
<tr>
<td align="left">FTP-Patator</td>
<td align="left">7938</td>
<td align="left">0.280421</td>
<td align="center">Tuesday</td>
</tr>
<tr>
<td align="left">SSH-Patator</td>
<td align="left">5897</td>
<td align="left">0.208320</td>
<td align="center">Tuesday</td>
</tr>
<tr>
<td align="left">DoS slowloris</td>
<td align="left">5796</td>
<td align="left">0.204752</td>
<td align="center">Wednesday</td>
</tr>
<tr>
<td align="left">DoS Slowhttptest</td>
<td align="left">5499</td>
<td align="left">0.194260</td>
<td align="center">Wednesday</td>
</tr>
<tr>
<td align="left">Bot</td>
<td align="left">1966</td>
<td align="left">0.069452</td>
<td align="center">Friday</td>
</tr>
<tr>
<td align="left">Web Attack � Brute Force</td>
<td align="left">1507</td>
<td align="left">0.053237</td>
<td align="center">Thursday</td>
</tr>
<tr>
<td align="left">Web Attack � XSS</td>
<td align="left">652</td>
<td align="left">0.023033</td>
<td align="center">Thursday</td>
</tr>
<tr>
<td align="left">Infiltration</td>
<td align="left">36</td>
<td align="left">0.001272</td>
<td align="center">Thursday</td>
</tr>
<tr>
<td align="left">Web Attack � Sql Injection</td>
<td align="left">21</td>
<td align="left">0.000742</td>
<td align="center">Thursday</td>
</tr>
<tr>
<td align="left">Heartbleed</td>
<td align="left">11</td>
<td align="left">0.000389</td>
<td align="center">Wednesday</td>
</tr>
</tbody></table>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://statics.liuhengfeng.xyz/Hexo/image-20240920141636136.png" alt="CIC-IDS2017标签值"></p>
<h4 id="检查标签列Label分布情况代码"><a href="#检查标签列Label分布情况代码" class="headerlink" title="检查标签列Label分布情况代码"></a><strong>检查标签列Label分布情况代码</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置文件夹路径</span></span><br><span class="line">folder_path = <span class="string">r&#x27;D:\Python Project\CIC-IDS2017\MachineLearningCVE&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取所有 CSV 文件</span></span><br><span class="line">csv_files = [f <span class="keyword">for</span> f <span class="keyword">in</span> os.listdir(folder_path) <span class="keyword">if</span> f.endswith(<span class="string">&#x27;.csv&#x27;</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 合并所有 CSV 文件</span></span><br><span class="line">df_list = []</span><br><span class="line">week_day_dict = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取文件中的星期几</span></span><br><span class="line"><span class="keyword">for</span> file <span class="keyword">in</span> csv_files:</span><br><span class="line">    df = pd.read_csv(os.path.join(folder_path, file))</span><br><span class="line">    df[<span class="string">&#x27;filename&#x27;</span>] = file  <span class="comment"># 在每个df里添加文件名列</span></span><br><span class="line">    df_list.append(df)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 提取星期几</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;Monday&#x27;</span> <span class="keyword">in</span> file:</span><br><span class="line">        week_day = <span class="string">&#x27;Monday&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="string">&#x27;Tuesday&#x27;</span> <span class="keyword">in</span> file:</span><br><span class="line">        week_day = <span class="string">&#x27;Tuesday&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="string">&#x27;Wednesday&#x27;</span> <span class="keyword">in</span> file:</span><br><span class="line">        week_day = <span class="string">&#x27;Wednesday&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="string">&#x27;Thursday&#x27;</span> <span class="keyword">in</span> file:</span><br><span class="line">        week_day = <span class="string">&#x27;Thursday&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="string">&#x27;Friday&#x27;</span> <span class="keyword">in</span> file:</span><br><span class="line">        week_day = <span class="string">&#x27;Friday&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="string">&#x27;Saturday&#x27;</span> <span class="keyword">in</span> file:</span><br><span class="line">        week_day = <span class="string">&#x27;Saturday&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="string">&#x27;Sunday&#x27;</span> <span class="keyword">in</span> file:</span><br><span class="line">        week_day = <span class="string">&#x27;Sunday&#x27;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        week_day = <span class="string">&#x27;Unknown&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 为每个文件记录对应的星期几</span></span><br><span class="line">    week_day_dict[file] = week_day</span><br><span class="line"></span><br><span class="line"><span class="comment"># 合成一个大的 DataFrame</span></span><br><span class="line">big_df = pd.concat(df_list, ignore_index=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看最后一列的标签列</span></span><br><span class="line">label_column = big_df.columns[-<span class="number">2</span>]  <span class="comment"># 最后一列是文件名，所以倒数第二列是标签列</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取标签与周几的对应关系</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_week_days_for_label</span>(<span class="params">df, label_column, week_day_dict</span>):</span><br><span class="line">    label_week_days = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> label <span class="keyword">in</span> df[label_column].unique():</span><br><span class="line">        <span class="keyword">if</span> label == <span class="string">&#x27;BENIGN&#x27;</span>:</span><br><span class="line">            <span class="keyword">continue</span>  <span class="comment"># BENIGN 不需要说明</span></span><br><span class="line">        week_days = df[df[label_column] == label][<span class="string">&#x27;filename&#x27;</span>].apply(<span class="keyword">lambda</span> x: week_day_dict[x]).unique()</span><br><span class="line">        label_week_days[label] = <span class="string">&#x27;, &#x27;</span>.join(week_days)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> label_week_days</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取每个标签出现在周几</span></span><br><span class="line">label_week_days = get_week_days_for_label(big_df, label_column, week_day_dict)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算各标签的数量和占比</span></span><br><span class="line">label_counts = big_df[label_column].value_counts()</span><br><span class="line">label_percentages = big_df[label_column].value_counts(normalize=<span class="literal">True</span>) * <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 DataFrame</span></span><br><span class="line">result = pd.DataFrame(&#123;</span><br><span class="line">    <span class="string">&#x27;Count&#x27;</span>: label_counts,</span><br><span class="line">    <span class="string">&#x27;Percentage&#x27;</span>: label_percentages,</span><br><span class="line">    <span class="string">&#x27;Week Days&#x27;</span>: label_counts.index.<span class="built_in">map</span>(label_week_days).fillna(<span class="string">&#x27;BENIGN&#x27;</span>)  <span class="comment"># 给每个类型加上出现在周几</span></span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印结果</span></span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p><strong>预处理流程如下</strong></p>
<ul>
<li><strong>数据加载</strong>：加载周一、周二、周三和周五的子数据集，将它们合并为一个大的 DataFrame</li>
<li><strong>缺失值检查与替换</strong><ul>
<li>检查每列中的缺失值（NaN），统计数据集中总的缺失值比例</li>
<li>查找并<strong>替换数据集中出现的正无穷大和负无穷大值</strong>，将它们<strong>替换为 <code>NaN</code></strong></li>
</ul>
</li>
<li><strong>填充缺失值</strong>：将所有的 <code>NaN</code> 替换为 <code>-999</code>，便于后续删除(不替换为-1，因为数据集中真有一些值是-1，防止这些行被误删)。</li>
<li><strong>删除多余的列</strong>：<ul>
<li>删除99%以上的值都是0的列。</li>
<li><del>删除缺失值和无限值（填充为<code>-1</code>）超过30%的列。</del></li>
</ul>
</li>
<li><strong>删除存在缺失或无限值的行</strong>：去除所有存在 <code>-999 </code>的行。</li>
<li><strong>统计标签分布</strong>：统计并输出最后一列（标签列）的各类别数量和占比。</li>
<li><strong>归一化：</strong>将整个DataFrame进行归一化，方便后续划分训练集和测试集</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://statics.liuhengfeng.xyz/Hexo/image-20240920145902653.png" alt="存在NaN值和Infinity值的行"></p>
<h4 id="归一化与smote的先后顺序"><a href="#归一化与smote的先后顺序" class="headerlink" title="归一化与smote的先后顺序"></a>归一化与smote的先后顺序</h4><p><strong>不能先归一化在使用smote平衡数据集</strong></p>
<p>在处理分类任务时，归一化和SMOTE的顺序通常是：</p>
<ol>
<li><strong>先进行SMOTE</strong>：先对训练集进行SMOTE采样来平衡样本。这样生成的合成样本会基于原始数据的特征值分布进行生成。</li>
<li><strong>再进行归一化</strong>：SMOTE处理完后再对数据进行归一化。这样可以确保所有样本（包括原始和合成的样本）在同一归一化的范围内。</li>
</ol>
<p>如果先归一化再使用SMOTE，生成的合成样本可能不会完全遵循归一化后的数据分布，导致数据表示不一致。因此，推荐先用SMOTE平衡样本，再对数据进行归一化处理。</p>
<h4 id="def-preprocessing-返回结果"><a href="#def-preprocessing-返回结果" class="headerlink" title="def preprocessing()返回结果"></a>def preprocessing()返回结果</h4><p>return dataset，last_column_name</p>
<ul>
<li>dataset：预处理后的数据集，<del>已经完成归一化</del>，但未划分训练集和测试集</li>
<li>last_column_name：最后一列的名称<code>Label</code>,可以不要</li>
</ul>
<h4 id="预处理代码"><a href="#预处理代码" class="headerlink" title="预处理代码"></a>预处理代码</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分隔线</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">printline</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;--------------------------------------------------\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocessing</span>():</span><br><span class="line">    <span class="comment"># 加载数据</span></span><br><span class="line">    df_monday = pd.read_csv(<span class="string">&#x27;MachineLearningCVE/Monday-WorkingHours.pcap_ISCX.csv&#x27;</span>)</span><br><span class="line">    df_tuesday = pd.read_csv(<span class="string">&#x27;MachineLearningCVE/Tuesday-WorkingHours.pcap_ISCX.csv&#x27;</span>)</span><br><span class="line">    df_wednesday = pd.read_csv(<span class="string">&#x27;MachineLearningCVE/Wednesday-workingHours.pcap_ISCX.csv&#x27;</span>)</span><br><span class="line">    df_friday_morning = pd.read_csv(<span class="string">&#x27;MachineLearningCVE/Friday-WorkingHours-Morning.pcap_ISCX.csv&#x27;</span>)</span><br><span class="line">    df_friday_afternoon_ddos = pd.read_csv(<span class="string">&#x27;MachineLearningCVE/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv&#x27;</span>)</span><br><span class="line">    df_friday_afternoon_portscan = pd.read_csv(<span class="string">&#x27;MachineLearningCVE/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 合并数据集</span></span><br><span class="line">    data = [df_monday, df_tuesday, df_wednesday, df_friday_morning, df_friday_afternoon_ddos, df_friday_afternoon_portscan]</span><br><span class="line">    df = pd.concat(data)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 输出数据集的形状</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;合并后的数据集 shape: <span class="subst">&#123;df.shape&#125;</span>&quot;</span>)</span><br><span class="line">    printline()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 检查缺失值</span></span><br><span class="line">    missing_value_count = df.isna().<span class="built_in">sum</span>()</span><br><span class="line">    total_cells = np.product(df.shape)</span><br><span class="line">    total_missing = missing_value_count.<span class="built_in">sum</span>()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;数据集中有 <span class="subst">&#123;total_cells&#125;</span> 个元素, 其中包含 <span class="subst">&#123;total_missing&#125;</span> 个 NaN 值&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;缺失率为 <span class="subst">&#123;total_missing / total_cells * <span class="number">100</span>&#125;</span>%&quot;</span>)</span><br><span class="line">    printline()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 查找并替换正无穷和负无穷值为 NaN</span></span><br><span class="line">    df_clean = df.replace([np.inf, -np.inf], np.nan)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;将数据集中的 Infinity 和 -Infinity 替换为 NaN&quot;</span>)</span><br><span class="line">    printline()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将所有 NaN 替换为 -999</span></span><br><span class="line">    df_clean = df_clean.replace(np.nan, -<span class="number">999</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;将所有 NaN 替换为 -999&quot;</span>)</span><br><span class="line">    printline()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 删除 99%以上值为0的列</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;删除99%以上值为0的列&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> column <span class="keyword">in</span> df_clean.columns:</span><br><span class="line">        count = (df_clean[column] == <span class="number">0</span>).<span class="built_in">sum</span>()</span><br><span class="line">        percent_of_zeros = (count / df_clean.shape[<span class="number">0</span>]) * <span class="number">100</span></span><br><span class="line">        <span class="keyword">if</span> percent_of_zeros &gt;= <span class="number">99.0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;删除列 : <span class="subst">&#123;column&#125;</span>, 百分比为 <span class="subst">&#123;percent_of_zeros&#125;</span>%&quot;</span>)</span><br><span class="line">            df_clean.drop(column, inplace=<span class="literal">True</span>, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;删除列后，剩余列数：<span class="subst">&#123;df_clean.shape[<span class="number">1</span>]&#125;</span>&quot;</span>)</span><br><span class="line">    printline()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 删除包含 -999 的行</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;删除包含 -999 的行&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;删除前的行数: <span class="subst">&#123;df_clean.shape[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line">    before_drop = df_clean.shape[<span class="number">0</span>]</span><br><span class="line">    df_clean = df_clean[(df_clean != -<span class="number">999</span>).<span class="built_in">all</span>(axis=<span class="number">1</span>)]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;删除后的行数: <span class="subst">&#123;df_clean.shape[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;一共删除了 <span class="subst">&#123;before_drop - df_clean.shape[<span class="number">0</span>]&#125;</span> 行&quot;</span>)</span><br><span class="line">    printline()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取最后一列的列名（标签列）</span></span><br><span class="line">    last_column_name = df_clean.columns[-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 统计标签列中各个类别的数量和占比</span></span><br><span class="line">    label_counts = df_clean[last_column_name].value_counts()</span><br><span class="line">    total_samples = <span class="built_in">len</span>(df_clean)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;预处理后包含 <span class="subst">&#123;total_samples&#125;</span> 条数据&quot;</span>)</span><br><span class="line">    printline()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 输出标签的分布和占比</span></span><br><span class="line">    <span class="keyword">for</span> label, count <span class="keyword">in</span> label_counts.items():</span><br><span class="line">        percentage = (count / total_samples) * <span class="number">100</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;label:<span class="number">28</span>&#125;</span> ---&gt; <span class="subst">&#123;count:<span class="number">10</span>&#125;</span>   占比 = <span class="subst">&#123;percentage:<span class="number">.8</span>f&#125;</span>%&quot;</span>)</span><br><span class="line"></span><br><span class="line">    printline()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 归一化数据</span></span><br><span class="line">    <span class="comment"># dataset = min_max_normalize(df_clean)</span></span><br><span class="line">    <span class="comment"># print(&quot;数据归一化完成&quot;)</span></span><br><span class="line">    <span class="comment"># printline()</span></span><br><span class="line">    <span class="comment"># 保存预处理后的数据到本地</span></span><br><span class="line">    <span class="comment"># dataset.to_csv(&#x27;MachineLearningCVE/Dataset.csv&#x27;, index=False)</span></span><br><span class="line">    <span class="keyword">return</span> df_clean, last_column_name</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据归一化函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">min_max_normalize</span>(<span class="params">df</span>):</span><br><span class="line">    df_normalized = df.copy()</span><br><span class="line">    <span class="keyword">for</span> column <span class="keyword">in</span> df_normalized.columns:</span><br><span class="line">        <span class="keyword">if</span> df_normalized[column].dtype != <span class="string">&#x27;object&#x27;</span>:  <span class="comment"># 排除非数值类型的列</span></span><br><span class="line">            min_val = df_normalized[column].<span class="built_in">min</span>()</span><br><span class="line">            max_val = df_normalized[column].<span class="built_in">max</span>()</span><br><span class="line">            <span class="keyword">if</span> max_val != min_val:</span><br><span class="line">                df_normalized[column] = (df_normalized[column] - min_val) / (max_val - min_val)</span><br><span class="line">    <span class="keyword">return</span> df_normalized</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    dataset_normalized, last_column_name = preprocessing()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;最后一列（标签列）为: <span class="subst">&#123;last_column_name&#125;</span>&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="划分训练集和测试集"><a href="#划分训练集和测试集" class="headerlink" title="划分训练集和测试集"></a>划分训练集和测试集</h2><p>按8:2的比例划分训练集和测试集，划分后的结果如下(未平衡数据集)</p>
<ul>
<li>x_train.shape : (1895400, 66)		训练集的X，1895400个样本，66个特征变量</li>
<li>y_train.shape : (1895400,)                      训练集的y，1895400个样本，1个标签列</li>
<li>X_test.shape  : (473850, 66)                   测试集的X，473850个样本，66个特征变量</li>
<li>y_test.shape  : (473850,)                         测试集的y，473850个样本，1个标签列</li>
</ul>
<h4 id="训练集"><a href="#训练集" class="headerlink" title="训练集"></a>训练集</h4><p><strong>说明</strong>：因为没选用周四的数据，所以只有11种类型，而不是原来的15种</p>
<table>
<thead>
<tr>
<th>类型</th>
<th>样本数</th>
<th>比例</th>
</tr>
</thead>
<tbody><tr>
<td>BENIGN</td>
<td>1451928</td>
<td>0.766027</td>
</tr>
<tr>
<td>DoS Hulk</td>
<td>184099</td>
<td>0.097129</td>
</tr>
<tr>
<td>PortScan</td>
<td>127043</td>
<td>0.067027</td>
</tr>
<tr>
<td>DDoS</td>
<td>102420</td>
<td>0.054036</td>
</tr>
<tr>
<td>DoS GoldenEye</td>
<td>8234</td>
<td>0.004344</td>
</tr>
<tr>
<td>FTP-Patator</td>
<td>6348</td>
<td>0.003349</td>
</tr>
<tr>
<td>SSH-Patator</td>
<td>4718</td>
<td>0.002489</td>
</tr>
<tr>
<td>DoS slowloris</td>
<td>4637</td>
<td>0.002446</td>
</tr>
<tr>
<td>DoS Slowhttptest</td>
<td>4399</td>
<td>0.002321</td>
</tr>
<tr>
<td>Bot</td>
<td>1565</td>
<td>0.000826</td>
</tr>
<tr>
<td>Heartbleed</td>
<td>9</td>
<td>0.000005</td>
</tr>
<tr>
<td><strong>异常样本总数</strong></td>
<td><strong>443472</strong></td>
<td><strong>0.233972</strong></td>
</tr>
</tbody></table>
<h4 id="测试集"><a href="#测试集" class="headerlink" title="测试集"></a>测试集</h4><table>
<thead>
<tr>
<th>类型</th>
<th>样本数</th>
<th>比例</th>
</tr>
</thead>
<tbody><tr>
<td>BENIGN</td>
<td>362982</td>
<td>0.766027</td>
</tr>
<tr>
<td>DoS Hulk</td>
<td>46025</td>
<td>0.097130</td>
</tr>
<tr>
<td>PortScan</td>
<td>31761</td>
<td>0.067028</td>
</tr>
<tr>
<td>DDoS</td>
<td>25605</td>
<td>0.054036</td>
</tr>
<tr>
<td>DoS GoldenEye</td>
<td>2059</td>
<td>0.004345</td>
</tr>
<tr>
<td>FTP-Patator</td>
<td>1587</td>
<td>0.003349</td>
</tr>
<tr>
<td>SSH-Patator</td>
<td>1179</td>
<td>0.002488</td>
</tr>
<tr>
<td>DoS slowloris</td>
<td>1159</td>
<td>0.002446</td>
</tr>
<tr>
<td>DoS Slowhttptest</td>
<td>1100</td>
<td>0.002321</td>
</tr>
<tr>
<td>Bot</td>
<td>391</td>
<td>0.000825</td>
</tr>
<tr>
<td>Heartbleed</td>
<td>2</td>
<td>0.000004</td>
</tr>
<tr>
<td><strong>异常样本总数</strong></td>
<td><strong>110,868</strong></td>
<td><strong>0.233972</strong></td>
</tr>
</tbody></table>
<h2 id="平衡训练集"><a href="#平衡训练集" class="headerlink" title="平衡训练集"></a>平衡训练集</h2><h4 id="使用Gsmote平衡数据集代码"><a href="#使用Gsmote平衡数据集代码" class="headerlink" title="使用Gsmote平衡数据集代码"></a>使用Gsmote平衡数据集代码</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">balance_training_set</span>(<span class="params">X_train, y_train</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    平衡训练数据集，使得每个类别的样本数量大致相等。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    参数:</span></span><br><span class="line"><span class="string">    X_train (pandas.DataFrame): 训练特征数据。</span></span><br><span class="line"><span class="string">    y_train (pandas.Series): 训练目标标签。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    返回:</span></span><br><span class="line"><span class="string">    str: 平衡后的数据集保存路径。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 检查传入的X_train和y_train形状</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;平衡前 X_train shape: <span class="subst">&#123;X_train.shape&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;平衡前 y_train shape: \n<span class="subst">&#123;pd.Series(y_train).value_counts()&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 平衡目标数量，根据需要调整sampling_strategy</span></span><br><span class="line">    target_counts = &#123;</span><br><span class="line">        <span class="string">&quot;DoS GoldenEye&quot;</span>: <span class="number">100000</span>,</span><br><span class="line">        <span class="string">&quot;FTP-Patator&quot;</span>: <span class="number">100000</span>,</span><br><span class="line">        <span class="string">&quot;SSH-Patator&quot;</span>: <span class="number">100000</span>,</span><br><span class="line">        <span class="string">&quot;DoS slowloris&quot;</span>: <span class="number">100000</span>,</span><br><span class="line">        <span class="string">&quot;DoS Slowhttptest&quot;</span>: <span class="number">80000</span>,</span><br><span class="line">        <span class="string">&quot;Bot&quot;</span>: <span class="number">80000</span>,</span><br><span class="line">        <span class="string">&quot;Heartbleed&quot;</span>: <span class="number">10000</span>,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化GeometricSMOTE</span></span><br><span class="line">    gsmote = GeometricSMOTE(random_state=<span class="number">42</span>,</span><br><span class="line">                            k_neighbors=<span class="number">5</span>,</span><br><span class="line">                            selection_strategy=<span class="string">&#x27;combined&#x27;</span>,</span><br><span class="line">                            sampling_strategy=target_counts)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用GeometricSMOTE对训练集进行平衡</span></span><br><span class="line">    X_resampled, y_resampled = gsmote.fit_resample(X_train, y_train)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打印平衡后的数据分布</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;平衡后 X_train shape: <span class="subst">&#123;X_resampled.shape&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;平衡后 y_train shape: \n<span class="subst">&#123;pd.Series(y_resampled).value_counts()&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将重新采样后的数据合并为新的DataFrame</span></span><br><span class="line">    df_resampled = pd.DataFrame(X_resampled, columns=X_train.columns)</span><br><span class="line">    df_resampled[<span class="string">&#x27;attack_cat&#x27;</span>] = y_resampled</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打乱数据集顺序</span></span><br><span class="line">    df_resampled = df_resampled.sample(frac=<span class="number">1</span>, random_state=<span class="number">42</span>).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;df_resampled shape: <span class="subst">&#123;df_resampled.shape&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;df_resampled[<span class="string">&#x27;attack_cat&#x27;</span>].value_counts()&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 保存重新采样后的数据集到CSV文件</span></span><br><span class="line">    balanced_dataset_path = <span class="string">r&#x27;.\balanced_training_set.csv&#x27;</span></span><br><span class="line">    df_resampled.to_csv(balanced_dataset_path, index=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">return</span> balanced_dataset_path</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="模型评估指标"><a href="#模型评估指标" class="headerlink" title="模型评估指标"></a>模型评估指标</h2><p>评估入侵检测系统性能时最常用的指标如下：</p>
<ul>
<li><p>Accuracy</p>
</li>
<li><p>Precision</p>
</li>
<li><p>Recall</p>
</li>
<li><p>F-Measure</p>
</li>
<li><p>FAR&#x2F;FPR</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://statics.liuhengfeng.xyz/Hexo/image-20240923103725851.png" alt="常用性能评估指标"></p>
</li>
</ul>
<h2 id="AE-DNN进行分类"><a href="#AE-DNN进行分类" class="headerlink" title="AE+DNN进行分类"></a>AE+DNN进行分类</h2><h4 id="代码如下"><a href="#代码如下" class="headerlink" title="代码如下"></a>代码如下</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler, LabelEncoder</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> data_preprocessing <span class="keyword">import</span> preprocessing, printline</span><br><span class="line"><span class="keyword">from</span> imbalance_process <span class="keyword">import</span> split_dataset, balance_training_set</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Model, Sequential</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Input, Dense</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report, confusion_matrix</span><br><span class="line"><span class="keyword">from</span> imbalance_process <span class="keyword">import</span> split_dataset, balance_training_set</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">normalize_and_map_labels</span>(<span class="params">X_train, X_test, y_train, y_test</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    归一化数据集，并将标签映射为二分类标签</span></span><br><span class="line"><span class="string">    BENIGN 映射为 0，其他类型映射为 1</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 检查 X_train 和 X_test 是否包含非数值列，如果有需要处理掉</span></span><br><span class="line">    X_train_numeric = X_train.select_dtypes(include=[np.number])</span><br><span class="line">    X_test_numeric = X_test.select_dtypes(include=[np.number])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化StandardScaler</span></span><br><span class="line">    scaler = StandardScaler()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 归一化训练集和测试集</span></span><br><span class="line">    X_train_scaled = scaler.fit_transform(X_train_numeric)</span><br><span class="line">    X_test_scaled = scaler.transform(X_test_numeric)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建新的二分类标签列：BENIGN = 0, others = 1</span></span><br><span class="line">    y_train_mapped = (y_train != <span class="string">&quot;BENIGN&quot;</span>).astype(<span class="built_in">int</span>)</span><br><span class="line">    y_test_mapped = (y_test != <span class="string">&quot;BENIGN&quot;</span>).astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将原有数据集替换成归一化后的数值数据</span></span><br><span class="line">    X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train_numeric.columns)</span><br><span class="line">    X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test_numeric.columns)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打印输出验证处理后的数据</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;归一化后的 X_train shape: <span class="subst">&#123;X_train_scaled_df.shape&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;归一化后的 X_test shape: <span class="subst">&#123;X_test_scaled_df.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> X_train_scaled_df, X_test_scaled_df, y_train_mapped, y_test_mapped</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_autoencoder</span>(<span class="params">input_dim, encoding_dim</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    构建并返回一个简单的自编码器模型</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    input_layer = Input(shape=(input_dim,))</span><br><span class="line">    encoder = Dense(encoding_dim, activation=<span class="string">&quot;relu&quot;</span>)(input_layer)</span><br><span class="line">    decoder = Dense(input_dim, activation=<span class="string">&quot;sigmoid&quot;</span>)(encoder)</span><br><span class="line">    autoencoder = Model(inputs=input_layer, outputs=decoder)</span><br><span class="line">    autoencoder.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;mse&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> autoencoder</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_ae_dnn</span>(<span class="params">X_train, X_test, y_train, y_test, encoding_dim=<span class="number">30</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    使用自编码器进行降维后，构建一个简单的DNN模型进行分类</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    input_dim = X_train.shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建自编码器</span></span><br><span class="line">    autoencoder = build_autoencoder(input_dim, encoding_dim)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练自编码器</span></span><br><span class="line">    autoencoder.fit(X_train, X_train, epochs=<span class="number">50</span>, batch_size=<span class="number">256</span>, shuffle=<span class="literal">True</span>, validation_data=(X_test, X_test))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># AE降维后的数据</span></span><br><span class="line">    encoder_model = Model(inputs=autoencoder.<span class="built_in">input</span>, outputs=autoencoder.layers[<span class="number">1</span>].output)</span><br><span class="line">    X_train_encoded = encoder_model.predict(X_train)</span><br><span class="line">    X_test_encoded = encoder_model.predict(X_test)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建DNN模型</span></span><br><span class="line">    dnn_model = Sequential([</span><br><span class="line">        Dense(<span class="number">128</span>, input_dim=encoding_dim, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">        Dense(<span class="number">64</span>, input_dim=encoding_dim, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">        Dense(<span class="number">32</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">        Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line">    ])</span><br><span class="line">    dnn_model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>, metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练DNN模型</span></span><br><span class="line">    dnn_model.fit(X_train_encoded, y_train, epochs=<span class="number">80</span>, batch_size=<span class="number">256</span>, validation_data=(X_test_encoded, y_test))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 预测并评估</span></span><br><span class="line">    y_pred = (dnn_model.predict(X_test_encoded) &gt; <span class="number">0.7</span>).astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 混淆矩阵和评估指标</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Confusion Matrix:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(confusion_matrix(y_test, y_pred))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Accuracy:&quot;</span>, accuracy_score(y_test, y_pred))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Precision:&quot;</span>, precision_score(y_test, y_pred))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Recall:&quot;</span>, recall_score(y_test, y_pred))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;F1 Score:&quot;</span>, f1_score(y_test, y_pred))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    X_train, X_test, y_train, y_test = split_dataset()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 步骤 2: 平衡训练集</span></span><br><span class="line">    X_train_resampled, X_test, y_train_resampled, y_test = balance_training_set(X_train, X_test, y_train, y_test)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 步骤 3: 归一化并映射标签</span></span><br><span class="line">    X_train_scaled, X_test_scaled, y_train_mapped, y_test_mapped = normalize_and_map_labels(X_train_resampled, X_test,</span><br><span class="line">                                                                                            y_train_resampled, y_test)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 步骤 4: 使用 AE + DNN 进行训练和评估</span></span><br><span class="line">    train_ae_dnn(X_train_scaled, X_test_scaled, y_train_mapped, y_test_mapped)</span><br></pre></td></tr></table></figure>

<h4 id="第一次"><a href="#第一次" class="headerlink" title="第一次"></a>第一次</h4><p>配置如下：</p>
<p>结果如下：</p>
<p>Confusion Matrix:<br>[[358699   4283]<br> [  1320 109548]]<br>Accuracy: 0.9881755829903978<br>Precision: 0.962374045734466<br>Recall: 0.9880939495616409<br>F1 Score: 0.9750644195123254</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://statics.liuhengfeng.xyz/Hexo/image-20240920212644732.png" alt="第一次实验结果"></p>
<h4 id="第二次"><a href="#第二次" class="headerlink" title="第二次"></a>第二次</h4><p>Confusion Matrix:<br>[[358016   4966]<br> [  1272 109596]]<br>Accuracy: 0.9868354964651261<br>Precision: 0.9566522930814755<br>Recall: 0.9885268968503085<br>F1 Score: 0.9723284389832764</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://statics.liuhengfeng.xyz/Hexo/image-20240920215651516.png" alt="第二次实验结果"></p>
<h4 id="第三次"><a href="#第三次" class="headerlink" title="第三次"></a>第三次</h4><p>配置如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">build_autoencoder</span>(<span class="params">input_dim, encoding_dim</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    构建并返回一个简单的自编码器模型</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    input_layer = Input(shape=(input_dim,))</span><br><span class="line">    encoder = Dense(encoding_dim, activation=<span class="string">&quot;relu&quot;</span>)(input_layer)</span><br><span class="line">    decoder = Dense(input_dim, activation=<span class="string">&quot;sigmoid&quot;</span>)(encoder)</span><br><span class="line">    autoencoder = Model(inputs=input_layer, outputs=decoder)</span><br><span class="line">    autoencoder.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;mse&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> autoencoder</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_ae_dnn</span>(<span class="params">X_train, X_test, y_train, y_test, encoding_dim=<span class="number">30</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    使用自编码器进行降维后，构建一个简单的DNN模型进行分类</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    input_dim = X_train.shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建自编码器</span></span><br><span class="line">    autoencoder = build_autoencoder(input_dim, encoding_dim)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练自编码器</span></span><br><span class="line">    autoencoder.fit(X_train, X_train, epochs=<span class="number">30</span>, batch_size=<span class="number">256</span>, shuffle=<span class="literal">True</span>, validation_data=(X_test, X_test))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># AE降维后的数据</span></span><br><span class="line">    encoder_model = Model(inputs=autoencoder.<span class="built_in">input</span>, outputs=autoencoder.layers[<span class="number">1</span>].output)</span><br><span class="line">    X_train_encoded = encoder_model.predict(X_train)</span><br><span class="line">    X_test_encoded = encoder_model.predict(X_test)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建DNN模型</span></span><br><span class="line">    dnn_model = Sequential([</span><br><span class="line">        Dense(<span class="number">128</span>, input_dim=encoding_dim, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">        Dense(<span class="number">64</span>, input_dim=encoding_dim, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">        Dense(<span class="number">32</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">        Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line">    ])</span><br><span class="line">    dnn_model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>, metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练DNN模型</span></span><br><span class="line">    dnn_model.fit(X_train_encoded, y_train, epochs=<span class="number">50</span>, batch_size=<span class="number">256</span>, validation_data=(X_test_encoded, y_test))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 预测并评估</span></span><br><span class="line">    y_pred = (dnn_model.predict(X_test_encoded) &gt; <span class="number">0.8</span>).astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 混淆矩阵和评估指标</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Confusion Matrix:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(confusion_matrix(y_test, y_pred))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Accuracy:&quot;</span>, accuracy_score(y_test, y_pred))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Precision:&quot;</span>, precision_score(y_test, y_pred))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Recall:&quot;</span>, recall_score(y_test, y_pred))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;F1 Score:&quot;</span>, f1_score(y_test, y_pred))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>结果如下:</p>
<p>Confusion Matrix:<br>[[360425   2557]<br> [  6934 103934]]<br>Accuracy: 0.9799704547852696<br>Precision: 0.9759885811946549<br>Recall: 0.9374571562578923<br>F1 Score: 0.9563349113678291</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://statics.liuhengfeng.xyz/Hexo/image-20240923214852169.png" alt="第三次"></p>
<h2 id="仅使用DNN"><a href="#仅使用DNN" class="headerlink" title="仅使用DNN"></a>仅使用DNN</h2><h4 id="代码如下-1"><a href="#代码如下-1" class="headerlink" title="代码如下"></a>代码如下</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler, LabelEncoder</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> data_preprocessing <span class="keyword">import</span> preprocessing, printline</span><br><span class="line"><span class="keyword">from</span> imbalance_process <span class="keyword">import</span> split_dataset, balance_training_set</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">normalize_and_map_labels</span>(<span class="params">X_train, X_test, y_train, y_test</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    归一化数据集，并将标签映射为二分类标签</span></span><br><span class="line"><span class="string">    BENIGN 映射为 0，其他类型映射为 1</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 检查 X_train 和 X_test 是否包含非数值列，如果有需要处理掉</span></span><br><span class="line">    X_train_numeric = X_train.select_dtypes(include=[np.number])</span><br><span class="line">    X_test_numeric = X_test.select_dtypes(include=[np.number])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化StandardScaler</span></span><br><span class="line">    scaler = StandardScaler()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 归一化训练集和测试集</span></span><br><span class="line">    X_train_scaled = scaler.fit_transform(X_train_numeric)</span><br><span class="line">    X_test_scaled = scaler.transform(X_test_numeric)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建新的二分类标签列：BENIGN = 0, others = 1</span></span><br><span class="line">    y_train_mapped = (y_train != <span class="string">&quot;BENIGN&quot;</span>).astype(<span class="built_in">int</span>)</span><br><span class="line">    y_test_mapped = (y_test != <span class="string">&quot;BENIGN&quot;</span>).astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将原有数据集替换成归一化后的数值数据</span></span><br><span class="line">    X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train_numeric.columns)</span><br><span class="line">    X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test_numeric.columns)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打印输出验证处理后的数据</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;归一化后的 X_train shape: <span class="subst">&#123;X_train_scaled_df.shape&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;归一化后的 X_test shape: <span class="subst">&#123;X_test_scaled_df.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> X_train_scaled_df, X_test_scaled_df, y_train_mapped, y_test_mapped</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_dnn</span>(<span class="params">X_train, X_test, y_train, y_test</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    直接使用 DNN 进行分类</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    input_dim = X_train.shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建 DNN 模型</span></span><br><span class="line">    dnn_model = Sequential([</span><br><span class="line">        Dense(<span class="number">128</span>, input_dim=input_dim, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">        Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">        Dense(<span class="number">32</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">        Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line">    ])</span><br><span class="line">    dnn_model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>, metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练 DNN 模型</span></span><br><span class="line">    dnn_model.fit(X_train, y_train, epochs=<span class="number">50</span>, batch_size=<span class="number">256</span>, validation_data=(X_test, y_test))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 预测并评估</span></span><br><span class="line">    y_pred = (dnn_model.predict(X_test) &gt; <span class="number">0.5</span>).astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 混淆矩阵和评估指标</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Confusion Matrix:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(confusion_matrix(y_test, y_pred))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Accuracy:&quot;</span>, accuracy_score(y_test, y_pred))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Precision:&quot;</span>, precision_score(y_test, y_pred))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Recall:&quot;</span>, recall_score(y_test, y_pred))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;F1 Score:&quot;</span>, f1_score(y_test, y_pred))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    X_train, X_test, y_train, y_test = split_dataset()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 步骤 2: 平衡训练集</span></span><br><span class="line">    X_train_resampled, X_test, y_train_resampled, y_test = balance_training_set(X_train, X_test, y_train, y_test)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 步骤 3: 归一化并映射标签</span></span><br><span class="line">    X_train_scaled, X_test_scaled, y_train_mapped, y_test_mapped = normalize_and_map_labels(X_train_resampled, X_test,</span><br><span class="line">                                                                                            y_train_resampled, y_test)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 步骤 4: 直接使用 DNN 进行训练和评估</span></span><br><span class="line">    train_dnn(X_train_scaled, X_test_scaled, y_train_mapped, y_test_mapped)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>不使用AE, 用完AE就是负优化，垃圾，直接用DNN就能到99%，用完AE变97%，再看看能套什么别的</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://statics.liuhengfeng.xyz/Hexo/image-20240923222916588.png" alt="仅使用DNN"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://statics.liuhengfeng.xyz/Hexo/image-20240924151931720.png" alt="仅DNN(二)"></p>
<h4 id="为什么只做了数据处理和平衡数据集就能达到如此夸张的识别率？"><a href="#为什么只做了数据处理和平衡数据集就能达到如此夸张的识别率？" class="headerlink" title="为什么只做了数据处理和平衡数据集就能达到如此夸张的识别率？"></a>为什么只做了数据处理和平衡数据集就能达到如此夸张的识别率？</h4><p>数据集中并没有像UNSW-NB15一样既有攻击类型，又有0-1标签列；之前使用UNSW-NB15划分数据集测试集后准确率接近100%是因为有<code>attack_cat</code>列没有去除，而标签列是<code>label</code>,所以导致数据泄露直接根据<code>attack_cat</code>就能识别出0或1，但是CIC-IDS2017不存在这种问题，为什么还是有如此夸张的识别率？<strong>跟平衡数据集有无关系？不适用Gsmote平衡数据集还能实现该结果吗？</strong></p>
<h2 id="多分类"><a href="#多分类" class="headerlink" title="多分类"></a>多分类</h2><h4 id="多分类第一次"><a href="#多分类第一次" class="headerlink" title="多分类第一次"></a>多分类第一次</h4><p><strong>进行多分类结果也很好</strong></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://statics.liuhengfeng.xyz/Hexo/image-20240924154716541.png" alt="多分类结果"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://statics.liuhengfeng.xyz/Hexo/image-20240924160004320.png" alt="多分类混淆矩阵一"></p>
<h4 id="多分类第二次"><a href="#多分类第二次" class="headerlink" title="多分类第二次"></a>多分类第二次</h4><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://statics.liuhengfeng.xyz/Hexo/image-20240924162331099.png" alt="多分类结果二"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://statics.liuhengfeng.xyz/Hexo/image-20240924162302205.png" alt="多分类混淆矩阵二"></p>
<h4 id="各类别分类结果"><a href="#各类别分类结果" class="headerlink" title="各类别分类结果"></a>各类别分类结果</h4><ul>
<li><p>BENIGN<br> 准确率Accuracy: 0.9894<br> 精确率Precision: 0.9989<br> 召回率Recall: 0.9904<br> F1分数: 0.9947<br> 误报率FAR: 0.0034</p>
</li>
<li><p>Bot<br> 准确率Accuracy: 0.2160<br> 精确率Precision: 0.2172<br> 召回率Recall: 0.9744<br> F1分数: 0.3552<br> 误报率FAR: 0.0029</p>
</li>
<li><p>DDoS<br> 准确率Accuracy: 0.9597<br> 精确率Precision: 0.9618<br> 召回率Recall: 0.9977<br> F1分数: 0.9794<br> 误报率FAR: 0.0023</p>
</li>
<li><p>DoS GoldenEye<br> 准确率Accuracy: 0.9518<br> 精确率Precision: 0.9631<br> 召回率Recall: 0.9879<br> F1分数: 0.9753<br> 误报率FAR: 0.0002</p>
</li>
<li><p>DoS Hulk<br> 准确率Accuracy: 0.9715<br> 精确率Precision: 0.9807<br> 召回率Recall: 0.9904<br> F1分数: 0.9855<br> 误报率FAR: 0.0021</p>
</li>
<li><p>DoS Slowhttptest<br> 准确率Accuracy: 0.8507<br> 精确率Precision: 0.8665<br> 召回率Recall: 0.9791<br> F1分数: 0.9193<br> 误报率FAR: 0.0004</p>
</li>
<li><p>DoS slowloris<br>  准确率Accuracy: 0.8741<br>  精确率Precision: 0.8878<br>  召回率Recall: 0.9827<br>  F1分数: 0.9328<br>  误报率FAR: 0.0003</p>
</li>
<li><p>FTP-Patator<br> 准确率Accuracy: 0.9862<br> 精确率Precision: 0.9931<br> 召回率Recall: 0.9931<br> F1分数: 0.9931<br> 误报率FAR: 0.0000</p>
</li>
<li><p>Heartbleed<br>  准确率Accuracy: 1.0000<br>  精确率Precision: 1.0000<br>  召回率Recall: 1.0000<br>  F1分数: 1.0000<br>  误报率FAR: 0.0000</p>
</li>
<li><p>PortScan<br>  准确率Accuracy: 0.9965<br>  精确率Precision: 0.9993<br>  召回率Recall: 0.9972<br>  F1分数: 0.9983<br>  误报率FAR: 0.0000</p>
</li>
<li><p>SSH-Patator<br> 准确率Accuracy: 0.9165<br> 精确率Precision: 0.9275<br> 召回率Recall: 0.9873<br> F1分数: 0.9565<br> 误报率FAR: 0.0002</p>
</li>
<li><p><strong>总体准确率: 0.9912</strong></p>
</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://statics.liuhengfeng.xyz/Hexo/image-20240924184003603.png" alt="多分类混淆矩阵三"></p>
</article><div class="post-copyright"><div class="post-copyright__title"><span class="post-copyright-info"><h>CIC-IDS2017使用DNN进行分类</h></span></div><div class="post-copyright__type"><span class="post-copyright-info"><a href="https://liuhengfeng.xyz/posts/6a858c3d.html">https://liuhengfeng.xyz/posts/6a858c3d.html</a></span></div><div class="post-copyright-m"><div class="post-copyright-m-info"><div class="post-copyright-a"><h>作者</h><div class="post-copyright-cc-info"><h>iKun</h></div></div><div class="post-copyright-c"><h>发布于</h><div class="post-copyright-cc-info"><h>2024-09-20</h></div></div><div class="post-copyright-u"><h>更新于</h><div class="post-copyright-cc-info"><h>2024-09-23</h></div></div><div class="post-copyright-c"><h>许可协议</h><div class="post-copyright-cc-info"><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a rel="noopener" target="_blank" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></div></div></div></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/CIC-IDS2017/">CIC-IDS2017</a><a class="post-meta__tags" href="/tags/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E5%88%86%E7%B1%BB/">异常检测分类</a><a class="post-meta__tags" href="/tags/DNN/">DNN</a></div><div class="post_share"><div class="social-share" data-image="https://statics.liuhengfeng.xyz/Hexo/u%3D1968668429%2C2104382916%26fm%3D253%26fmt%3Dauto%26app%3D138%26f%3DJPEG.webp" data-sites="twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/196d9062.html" title="CIC-IDS2017使用CNN进行分类"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">CIC-IDS2017使用CNN进行分类</div></div></a></div><div class="next-post pull-right"><a href="/posts/93c9aa62.html" title="2024"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">2024</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/196d9062.html" title="CIC-IDS2017使用CNN进行分类"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-09-27</div><div class="title">CIC-IDS2017使用CNN进行分类</div></div></a></div><div><a href="/posts/91578d31.html" title="UNSW-NB15使用CNN进行分类"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-09-28</div><div class="title">UNSW-NB15使用CNN进行分类</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.</span> <span class="toc-text">数据集介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%89%B9%E5%BE%81"><span class="toc-number">1.0.1.</span> <span class="toc-text">特征</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E6%94%BB%E5%87%BB%E7%B1%BB%E5%9E%8B%E5%88%86%E5%B8%83%E6%83%85%E5%86%B5"><span class="toc-number">1.0.2.</span> <span class="toc-text">数据集攻击类型分布情况</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A3%80%E6%9F%A5%E6%A0%87%E7%AD%BE%E5%88%97Label%E5%88%86%E5%B8%83%E6%83%85%E5%86%B5%E4%BB%A3%E7%A0%81"><span class="toc-number">1.0.3.</span> <span class="toc-text">检查标签列Label分布情况代码</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">2.</span> <span class="toc-text">数据预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BD%92%E4%B8%80%E5%8C%96%E4%B8%8Esmote%E7%9A%84%E5%85%88%E5%90%8E%E9%A1%BA%E5%BA%8F"><span class="toc-number">2.0.1.</span> <span class="toc-text">归一化与smote的先后顺序</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#def-preprocessing-%E8%BF%94%E5%9B%9E%E7%BB%93%E6%9E%9C"><span class="toc-number">2.0.2.</span> <span class="toc-text">def preprocessing()返回结果</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%A2%84%E5%A4%84%E7%90%86%E4%BB%A3%E7%A0%81"><span class="toc-number">2.0.3.</span> <span class="toc-text">预处理代码</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%92%E5%88%86%E8%AE%AD%E7%BB%83%E9%9B%86%E5%92%8C%E6%B5%8B%E8%AF%95%E9%9B%86"><span class="toc-number">3.</span> <span class="toc-text">划分训练集和测试集</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E9%9B%86"><span class="toc-number">3.0.1.</span> <span class="toc-text">训练集</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B5%8B%E8%AF%95%E9%9B%86"><span class="toc-number">3.0.2.</span> <span class="toc-text">测试集</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B9%B3%E8%A1%A1%E8%AE%AD%E7%BB%83%E9%9B%86"><span class="toc-number">4.</span> <span class="toc-text">平衡训练集</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8Gsmote%E5%B9%B3%E8%A1%A1%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%A3%E7%A0%81"><span class="toc-number">4.0.1.</span> <span class="toc-text">使用Gsmote平衡数据集代码</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87"><span class="toc-number">5.</span> <span class="toc-text">模型评估指标</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#AE-DNN%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB"><span class="toc-number">6.</span> <span class="toc-text">AE+DNN进行分类</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%A6%82%E4%B8%8B"><span class="toc-number">6.0.1.</span> <span class="toc-text">代码如下</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E6%AC%A1"><span class="toc-number">6.0.2.</span> <span class="toc-text">第一次</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E6%AC%A1"><span class="toc-number">6.0.3.</span> <span class="toc-text">第二次</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E6%AC%A1"><span class="toc-number">6.0.4.</span> <span class="toc-text">第三次</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%85%E4%BD%BF%E7%94%A8DNN"><span class="toc-number">7.</span> <span class="toc-text">仅使用DNN</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%A6%82%E4%B8%8B-1"><span class="toc-number">7.0.1.</span> <span class="toc-text">代码如下</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8F%AA%E5%81%9A%E4%BA%86%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E5%92%8C%E5%B9%B3%E8%A1%A1%E6%95%B0%E6%8D%AE%E9%9B%86%E5%B0%B1%E8%83%BD%E8%BE%BE%E5%88%B0%E5%A6%82%E6%AD%A4%E5%A4%B8%E5%BC%A0%E7%9A%84%E8%AF%86%E5%88%AB%E7%8E%87%EF%BC%9F"><span class="toc-number">7.0.2.</span> <span class="toc-text">为什么只做了数据处理和平衡数据集就能达到如此夸张的识别率？</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E5%88%86%E7%B1%BB"><span class="toc-number">8.</span> <span class="toc-text">多分类</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%9A%E5%88%86%E7%B1%BB%E7%AC%AC%E4%B8%80%E6%AC%A1"><span class="toc-number">8.0.1.</span> <span class="toc-text">多分类第一次</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%9A%E5%88%86%E7%B1%BB%E7%AC%AC%E4%BA%8C%E6%AC%A1"><span class="toc-number">8.0.2.</span> <span class="toc-text">多分类第二次</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%84%E7%B1%BB%E5%88%AB%E5%88%86%E7%B1%BB%E7%BB%93%E6%9E%9C"><span class="toc-number">8.0.3.</span> <span class="toc-text">各类别分类结果</span></a></li></ol></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div class="footer-wrap" id="footer-wrap"> <div class="copyright">&copy;2023 - 2024 By iKun</div><div class="footer_custom_text">多读书 多看报 少吃零食 多睡觉</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button><button id="go-down" type="button" title="直达底部" onclick="btf.scrollToDest(document.body.scrollHeight, 500)"><i class="fas fa-arrow-down"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@5.2.0/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.8.8/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.16/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"></div><canvas id="universe"></canvas><script defer src="/js/universe.js"></script><script async src="https://statics.liuhengfeng.xyz/js/fps.js"></script><script src="https://statics.liuhengfeng.xyz/js/jquery-3.6.1.min.js"></script><script src="https://statics.liuhengfeng.xyz/js/txmap.js"></script><canvas id="snow"></canvas><script async src="https://statics.liuhengfeng.xyz/js/snow.js"></script><script src="https://statics.liuhengfeng.xyz/js/jquery-3.6.3.min.js"></script><script async data-pjax src="https://cdn.wpon.cn/2022-sucai/Gold-ingot.js"></script><script async data-pjax src="https://statics.liuhengfeng.xyz/js/newYear.js"></script><script async src="https://cdn1.tianli0.top/npm/vue@2.6.14/dist/vue.min.js"></script><script async src="https://cdn1.tianli0.top/npm/element-ui@2.15.6/lib/index.js"></script><script async src="https://statics.liuhengfeng.xyz/js/copyPrompt.js"></script><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/fireworks.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false#  open shake (抖動特效);
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.13.0"></script></div></div><!-- hexo injector body_end start --><script data-pjax>
  function butterfly_clock_anzhiyu_injector_config(){
    var parent_div_git = document.getElementsByClassName('card-widget card-announcement')[2];
    var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img class="entered loading" id="card-clock-loading" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading"/></div></div></div></div></div>';
    console.log('已挂载butterfly_clock_anzhiyu')
    if(parent_div_git) {
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var qweather_key = 'f89c5a6b949a4345a0d22f0ad5b040ea';
  var gaud_map_key = 'a36227a8c2b6dcd6b90a98920a06ac89';
  var baidu_ak_key = 'undefined';
  var flag = 0;
  var clock_rectangle = '112.982279,28.19409';
  var clock_default_rectangle_enable = 'false';

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_clock_anzhiyu_injector_config();
  }
  else if (epage === cpage){
    butterfly_clock_anzhiyu_injector_config();
  }
  </script><script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script><script data-pjax src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.js"></script><script data-pjax>
  function butterfly_footer_beautify_injector_config(){
    var parent_div_git = document.getElementById('footer-wrap');
    var item_html = '<p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" data-title="博客框架为Hexo" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&amp;logo=hexo" alt=""/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px" data-title="博客主题为Butterfly" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Theme-Butterfly-d021d6?style=flat&amp;logo=buefy&amp;color=purple" alt=""/></a><a class="github-badge" target="_blank" href="https://pages.github.com/" style="margin-inline:5px" data-title="本站项目托管于Github Pages" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Source-Github%20Pages-d021d6?style=flat&amp;logo=githubpages&amp;color=brown" alt=""/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" data-title="GitHub万岁" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Thanks-Github-d021d6?style=flat&amp;logo=GitHub&amp;color=indigo" alt=""/></a><a class="github-badge" target="_blank" href="https://www.alibabacloud.com/zh/product/content-delivery-network?_p_lc=1" style="margin-inline:5px" data-title="网站资源使用阿里云CDN加速" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/CDN-%E9%98%BF%E9%87%8C%E4%BA%91CDN-d021d6?style=flat&amp;logo=speedtest&amp;color=blue" alt=""/></a><a class="github-badge" target="_blank" href="https://www.aliyun.com/benefit" style="margin-inline:5px" data-title="本站图床部署于阿里云OSS" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/OSS-%E9%98%BF%E9%87%8C%E4%BA%91OSS-d021d6?style=flat&amp;logo=alibabacloud&amp;color=orange" alt=""/></a><a class="github-badge" target="_blank" href="https://beian.miit.gov.cn" style="margin-inline:5px" data-title="网站备案号" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/ICP-%E6%A1%82ICP%E5%A4%872023012461%E5%8F%B7-d021d6?style=flat&amp;logo=brandfolder&amp;color=yellow" alt=""/></a><a class="github-badge" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" style="margin-inline:5px" data-title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&amp;logo=creativecommons" alt=""/></a></p>';
    console.log('已挂载butterfly_footer_beautify')
    parent_div_git.insertAdjacentHTML("beforeend",item_html)
    }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_footer_beautify_injector_config();
  }
  else if (epage === cpage){
    butterfly_footer_beautify_injector_config();
  }
  </script><div class="js-pjax"><script async="async">var arr = document.getElementsByClassName('recent-post-item');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__backInRight');
    arr[i].setAttribute('data-wow-duration', '1s');
    arr[i].setAttribute('data-wow-delay', '500ms');
    arr[i].setAttribute('data-wow-offset', '100');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('card-widget');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__backInLeft');
    arr[i].setAttribute('data-wow-duration', '1s');
    arr[i].setAttribute('data-wow-delay', '500ms');
    arr[i].setAttribute('data-wow-offset', '100');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('footer-wrap');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__backInUp');
    arr[i].setAttribute('data-wow-duration', '1s');
    arr[i].setAttribute('data-wow-delay', '600ms');
    arr[i].setAttribute('data-wow-offset', '100');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('show');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__fadeInDown');
    arr[i].setAttribute('data-wow-duration', '1s');
    arr[i].setAttribute('data-wow-delay', '500ms');
    arr[i].setAttribute('data-wow-offset', '100');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('is-center');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__backInLeft');
    arr[i].setAttribute('data-wow-duration', '1s');
    arr[i].setAttribute('data-wow-delay', '500ms');
    arr[i].setAttribute('data-wow-offset', '100');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('card-info-data');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__backInLeft');
    arr[i].setAttribute('data-wow-duration', '1s');
    arr[i].setAttribute('data-wow-delay', '500ms');
    arr[i].setAttribute('data-wow-offset', '100');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('card-info-social-icons');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__backInLeft');
    arr[i].setAttribute('data-wow-duration', '1s');
    arr[i].setAttribute('data-wow-delay', '600ms');
    arr[i].setAttribute('data-wow-offset', '100');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('card-info-btn');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__backInLeft');
    arr[i].setAttribute('data-wow-duration', '1s');
    arr[i].setAttribute('data-wow-delay', '500ms');
    arr[i].setAttribute('data-wow-offset', '100');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script></div><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow.min.js"></script><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow_init.js"></script><!-- hexo injector body_end end --></body></html>